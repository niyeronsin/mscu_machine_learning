{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCA 5622: *I’m Something of a Painter Myself* – Kaggle Mini Project\n",
    "\n",
    "**Name:** Olaniyi Nafiu\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "The goal of this project is to practice building and training generative deep learning models using Generative Adversarial Networks (GANs). Specifically, the task is to generate images in the style of Claude Monet.\n",
    "\n",
    "The GAN model consists of two neural networks:\n",
    "\n",
    "- **Generator:** Attempts to create realistic Monet-style images to fool the discriminator.\n",
    "- **Discriminator:** Attempts to distinguish between real Monet paintings and those generated by the generator.\n",
    "\n",
    "---\n",
    "\n",
    "## Task\n",
    "\n",
    "Build a GAN that generates **7,000 to 10,000** Monet-style images.\n",
    "\n",
    "---\n",
    "\n",
    "## Data Description\n",
    "\n",
    "**Evaluation Metric:** MiFID (Memorization-informed Frechet Inception Distance) score.\n",
    "\n",
    "### Input Data\n",
    "\n",
    "The dataset contains four directories:\n",
    "\n",
    "- `monet_tfrec/`: 300 Monet paintings in TFRecord format (256×256)\n",
    "- `monet_jpg/`: 300 Monet paintings in JPEG format (256×256)\n",
    "- `photo_tfrec/`: 7,028 photos in TFRecord format (256×256)\n",
    "- `photo_jpg/`: 7,028 photos in JPEG format (256×256)\n",
    "\n",
    "- **Monet directories:** Contain Monet paintings used to train the model.\n",
    "- **Photo directories:** Contain real-world photos to be transformed into Monet-style images.\n",
    "\n",
    "### Output Requirements\n",
    "\n",
    "- **Number of images:** 7,000 to 10,000\n",
    "- **Image size:** 256 × 256 × 3 (RGB)\n",
    "- **Submission format:** A single ZIP file named `images.zip` containing all generated images\n",
    "\n",
    "---\n",
    "\n",
    "## Reference\n",
    "\n",
    "[Project Data on Kaggle](https://www.kaggle.com/competitions/gan-getting-started/data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:58:19.678187Z",
     "iopub.status.busy": "2025-06-22T17:58:19.677969Z",
     "iopub.status.idle": "2025-06-22T17:58:41.330053Z",
     "shell.execute_reply": "2025-06-22T17:58:41.329469Z",
     "shell.execute_reply.started": "2025-06-22T17:58:19.678171Z"
    }
   },
   "outputs": [],
   "source": [
    "# All Imports\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:58:41.332410Z",
     "iopub.status.busy": "2025-06-22T17:58:41.331988Z",
     "iopub.status.idle": "2025-06-22T17:58:41.459595Z",
     "shell.execute_reply": "2025-06-22T17:58:41.459030Z",
     "shell.execute_reply.started": "2025-06-22T17:58:41.332391Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "monet_dir = \"/kaggle/input/gan-getting-started/monet_jpg\"\n",
    "photo_dir = \"/kaggle/input/gan-getting-started/photo_jpg\"\n",
    "\n",
    "def get_image_paths(directory):\n",
    "    return sorted(glob.glob(os.path.join(directory, \"*.jpg\")))\n",
    "\n",
    "monet_images = get_image_paths(monet_dir)\n",
    "photo_images = get_image_paths(photo_dir)\n",
    "\n",
    "print(f\"Number of Monet images: {len(monet_images)}\")\n",
    "print(f\"Number of Photo images: {len(photo_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:58:41.460701Z",
     "iopub.status.busy": "2025-06-22T17:58:41.460405Z",
     "iopub.status.idle": "2025-06-22T17:58:42.223368Z",
     "shell.execute_reply": "2025-06-22T17:58:42.222731Z",
     "shell.execute_reply.started": "2025-06-22T17:58:41.460676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preview a few images\n",
    "def show_sample_images(image_paths, title, num=5):\n",
    "    fig, axs = plt.subplots(1, num, figsize=(15, 5))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    for i, ax in enumerate(axs):\n",
    "        img = Image.open(image_paths[i])\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "show_sample_images(monet_images, \"Sample Monet Paintings\")\n",
    "show_sample_images(photo_images, \"Sample Real-World Photos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "I'll be using Cycle GAN for developing the models. It is designed for unpaired image-to-image translation. \n",
    "\n",
    "### Components\n",
    "1. Generator G (Photo → Monet): Learns to paint a photo in Monet’s style.\n",
    "2. Generator F (Monet → Photo): Acts as the inverse. Helps ensure cycle consistency.\n",
    "3. Discriminator D_Y (Monet domain): Tries to tell real Monet paintings from fake ones created by G.\n",
    "4. Discriminator D_X (Photo domain): Tries to tell real photos from reconstructions by F.\n",
    "\n",
    "### Loss Functions\n",
    "\n",
    "To train CycleGAN effectively, several loss functions are used together:\n",
    "\n",
    "#### 1. Adversarial Loss\n",
    "\n",
    "Ensures that generated images are indistinguishable from real ones within each domain. It uses a standard GAN loss (typically least squares GAN loss):\n",
    "\n",
    "- For G and D<sub>Y</sub>:  \n",
    "  `L_GAN(G, D_Y, X, Y) = E_y[(D_Y(y) - 1)²] + E_x[D_Y(G(x))²]`\n",
    "\n",
    "- For F and D<sub>X</sub>:  \n",
    "  `L_GAN(F, D_X, Y, X) = E_x[(D_X(x) - 1)²] + E_y[D_X(F(y))²]`\n",
    "\n",
    "#### 2. Cycle Consistency Loss\n",
    "\n",
    "Encourages the mappings to be consistent:\n",
    "\n",
    "- If we translate a photo to Monet and back, we should get the original photo: `F(G(photo)) ≈ photo`\n",
    "- Likewise, `G(F(monet)) ≈ monet`\n",
    "\n",
    "The loss is:  \n",
    "`L_cycle(G, F) = E_x[‖F(G(x)) − x‖₁] + E_y[‖G(F(y)) − y‖₁]`\n",
    "\n",
    "This helps preserve the semantic content of the original images.\n",
    "\n",
    "#### 3. Identity Loss (Optional)\n",
    "\n",
    "Encourages the generators to preserve color and structure when the input is already from the target domain:\n",
    "\n",
    "- `G(monet) ≈ monet`  \n",
    "- `F(photo) ≈ photo`\n",
    "\n",
    "The loss is:  \n",
    "`L_identity(G, F) = E_y[‖G(y) − y‖₁] + E_x[‖F(x) − x‖₁]`\n",
    "\n",
    "This regularization helps stabilize training and preserve low-level details.\n",
    "\n",
    "#### 4. Total Objective\n",
    "\n",
    "The total loss combines all components:\n",
    "`L_total = L_GAN(G, D_Y) + L_GAN(F, D_X) + λ_cycle * L_cycle + λ_id * L_identity`\n",
    "\n",
    "Where:  \n",
    "- `λ_cycle` (typically 10) controls the weight of cycle consistency  \n",
    "- `λ_id` (optional, typically 0.5 or 0) controls the weight of identity loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:58:42.224317Z",
     "iopub.status.busy": "2025-06-22T17:58:42.224076Z",
     "iopub.status.idle": "2025-06-22T17:58:45.052046Z",
     "shell.execute_reply": "2025-06-22T17:58:45.051171Z",
     "shell.execute_reply.started": "2025-06-22T17:58:42.224296Z"
    }
   },
   "outputs": [],
   "source": [
    "## Preprocess Images\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "BATCH_SIZE = 1\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Normalize images to [-1, 1]\n",
    "def preprocess_image(file_path):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1.0\n",
    "    return image\n",
    "\n",
    "\n",
    "# Build dataset\n",
    "def build_dataset(image_paths, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "monet_ds = build_dataset(monet_images)\n",
    "photo_ds = build_dataset(photo_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:58:45.053087Z",
     "iopub.status.busy": "2025-06-22T17:58:45.052825Z",
     "iopub.status.idle": "2025-06-22T17:58:45.579749Z",
     "shell.execute_reply": "2025-06-22T17:58:45.578933Z",
     "shell.execute_reply.started": "2025-06-22T17:58:45.053068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize sample image after pre_processing\n",
    "def show_sample(ds, title):\n",
    "    for img in ds.take(1):\n",
    "        img = (img[0] + 1.0) / 2.0\n",
    "        plt.imshow(img)\n",
    "        plt.title(title)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "show_sample(monet_ds, \"Sample Monet Image\")\n",
    "show_sample(photo_ds, \"Sample Photo Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:58:45.581386Z",
     "iopub.status.busy": "2025-06-22T17:58:45.580696Z",
     "iopub.status.idle": "2025-06-22T17:58:45.595505Z",
     "shell.execute_reply": "2025-06-22T17:58:45.594965Z",
     "shell.execute_reply.started": "2025-06-22T17:58:45.581362Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build models\n",
    "\n",
    "# Instance Normalization normalizes styles across each image individually, which is better for style transfers such as in this project.\n",
    "class InstanceNormalization(layers.Layer):\n",
    "    def __init__(self, epsilon=1e-5):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = self.add_weight(name='gamma',\n",
    "                                     shape=(input_shape[-1],),\n",
    "                                     initializer=\"ones\",\n",
    "                                     trainable=True)\n",
    "        self.beta = self.add_weight(name='beta',\n",
    "                                    shape=(input_shape[-1],),\n",
    "                                    initializer=\"zeros\",\n",
    "                                    trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        mean, var = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "        return self.gamma * (x - mean) / tf.sqrt(var + self.epsilon) + self.beta\n",
    "\n",
    "# Residual block is a small neural network that includes a skip connection. It allows the GAN to retain content structure and only allow minor style changes\n",
    "def residual_block(x, filters):\n",
    "    input_tensor = x\n",
    "    x = layers.Conv2D(filters, kernel_size=3, padding=\"same\")(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size=3, padding=\"same\")(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    return layers.Add()([input_tensor, x])\n",
    "\n",
    "\n",
    "# Generator used for both G and F\n",
    "def build_generator(input_shape=(256, 256, 3), name=\"generator\"):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial conv layer\n",
    "    x = layers.Conv2D(64, kernel_size=7, strides=1, padding=\"same\")(inputs)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # Downsample: d128, d256\n",
    "    x = layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(256, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # Residual blocks ×6\n",
    "    for _ in range(6):\n",
    "        x = residual_block(x, 256)\n",
    "\n",
    "    # Upsample: u128, u64\n",
    "    x = layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # Output layer\n",
    "    x = layers.Conv2D(3, kernel_size=7, strides=1, padding=\"same\", activation=\"tanh\")(x)\n",
    "\n",
    "    return tf.keras.Model(inputs, x, name=name)\n",
    "\n",
    "\n",
    "# Discriminator used for both D_X and D_Y\n",
    "def build_discriminator(input_shape=(256, 256, 3), name=\"discriminator\"):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(64, 4, strides=2, padding='same', kernel_initializer=initializer)(inp)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(128, 4, strides=2, padding='same', kernel_initializer=initializer)(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, 4, strides=2, padding='same', kernel_initializer=initializer)(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(512, 4, strides=1, padding='same', kernel_initializer=initializer)(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(1, 4, strides=1, padding='same', kernel_initializer=initializer)(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inp, outputs=x, name=name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:58:45.598230Z",
     "iopub.status.busy": "2025-06-22T17:58:45.598002Z",
     "iopub.status.idle": "2025-06-22T17:58:48.292196Z",
     "shell.execute_reply": "2025-06-22T17:58:48.291650Z",
     "shell.execute_reply.started": "2025-06-22T17:58:45.598214Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model instantiation\n",
    "gen_G = build_generator(name=\"G_photo2monet\")\n",
    "gen_F = build_generator(name=\"F_monet2photo\")\n",
    "\n",
    "disc_X = build_discriminator(name=\"D_photo\")\n",
    "disc_Y = build_discriminator(name=\"D_monet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:58:48.293160Z",
     "iopub.status.busy": "2025-06-22T17:58:48.292909Z",
     "iopub.status.idle": "2025-06-22T17:58:48.298560Z",
     "shell.execute_reply": "2025-06-22T17:58:48.298054Z",
     "shell.execute_reply.started": "2025-06-22T17:58:48.293133Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Loss Functions\n",
    "loss_obj = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "## Adversarial loss: goal is for loss of fake output to be close to 1\n",
    "def generator_loss(fake_output):\n",
    "    return loss_obj(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "## Discrimator loss: goal is for output to be 1 for real monet images and 0 for fake monet images\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = loss_obj(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = loss_obj(tf.zeros_like(fake_output), fake_output)\n",
    "    return (real_loss + fake_loss) * 0.5\n",
    "\n",
    "## Cycle consistency loss: ensures original image can be reconstructed\n",
    "def cycle_consistency_loss(real_image, cycled_image, lambda_cycle=10):\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "    return lambda_cycle * loss\n",
    "\n",
    "## Identity loss: ensures generator does not change input if it's already monet\n",
    "def identity_loss(real_image, same_image, lambda_identity=5):\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "    return lambda_identity * loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:58:48.299427Z",
     "iopub.status.busy": "2025-06-22T17:58:48.299253Z",
     "iopub.status.idle": "2025-06-22T17:58:48.333471Z",
     "shell.execute_reply": "2025-06-22T17:58:48.332813Z",
     "shell.execute_reply.started": "2025-06-22T17:58:48.299412Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model Optimization\n",
    "generator_lr = 2e-4\n",
    "discriminator_lr = 2e-4\n",
    "beta_1 = 0.5\n",
    "\n",
    "G_optimizer = tf.keras.optimizers.Adam(learning_rate=generator_lr, beta_1=beta_1)\n",
    "F_optimizer = tf.keras.optimizers.Adam(learning_rate=generator_lr, beta_1=beta_1)\n",
    "D_X_optimizer = tf.keras.optimizers.Adam(learning_rate=discriminator_lr, beta_1=beta_1)\n",
    "D_Y_optimizer = tf.keras.optimizers.Adam(learning_rate=discriminator_lr, beta_1=beta_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:58:48.334443Z",
     "iopub.status.busy": "2025-06-22T17:58:48.334170Z",
     "iopub.status.idle": "2025-06-22T17:58:48.572818Z",
     "shell.execute_reply": "2025-06-22T17:58:48.571897Z",
     "shell.execute_reply.started": "2025-06-22T17:58:48.334425Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:58:48.574358Z",
     "iopub.status.busy": "2025-06-22T17:58:48.574044Z",
     "iopub.status.idle": "2025-06-22T17:58:48.583257Z",
     "shell.execute_reply": "2025-06-22T17:58:48.582543Z",
     "shell.execute_reply.started": "2025-06-22T17:58:48.574326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Training Function\n",
    "@tf.function\n",
    "def train_step(real_photo, real_monet):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Generate fake images with generators\n",
    "        fake_monet = gen_G(real_photo, training=True)\n",
    "        fake_photo = gen_F(real_monet, training=True)\n",
    "\n",
    "        # Create cycle images for cycle consitency loss evaluation\n",
    "        cycled_photo = gen_F(fake_monet, training=True)\n",
    "        cycled_monet = gen_G(fake_photo, training=True)\n",
    "\n",
    "        # Create image mapping for identity loss evaluation\n",
    "        same_photo = gen_F(real_photo, training=True)\n",
    "        same_monet = gen_G(real_monet, training=True)\n",
    "\n",
    "        # Discriminator outputs\n",
    "        disc_real_monet = disc_Y(real_monet, training=True)\n",
    "        disc_fake_monet = disc_Y(fake_monet, training=True)\n",
    "\n",
    "        disc_real_photo = disc_X(real_photo, training=True)\n",
    "        disc_fake_photo = disc_X(fake_photo, training=True)\n",
    "\n",
    "        # Generator adversarial losses\n",
    "        G_gan_loss = generator_loss(disc_fake_monet)\n",
    "        F_gan_loss = generator_loss(disc_fake_photo)\n",
    "\n",
    "        # Cycle consistency losses\n",
    "        cycle_loss_G = cycle_consistency_loss(real_photo, cycled_photo)\n",
    "        cycle_loss_F = cycle_consistency_loss(real_monet, cycled_monet)\n",
    "\n",
    "        # Identity losses\n",
    "        id_loss_G = identity_loss(real_monet, same_monet)\n",
    "        id_loss_F = identity_loss(real_photo, same_photo)\n",
    "\n",
    "        # Total generator losses\n",
    "        G_total_loss = G_gan_loss + cycle_loss_G + id_loss_G\n",
    "        F_total_loss = F_gan_loss + cycle_loss_F + id_loss_F\n",
    "\n",
    "        # Discriminator losses\n",
    "        D_Y_loss = discriminator_loss(disc_real_monet, disc_fake_monet)\n",
    "        D_X_loss = discriminator_loss(disc_real_photo, disc_fake_photo)\n",
    "\n",
    "    # Compute gradients\n",
    "    G_gradients = tape.gradient(G_total_loss, gen_G.trainable_variables)\n",
    "    F_gradients = tape.gradient(F_total_loss, gen_F.trainable_variables)\n",
    "    D_Y_gradients = tape.gradient(D_Y_loss, disc_Y.trainable_variables)\n",
    "    D_X_gradients = tape.gradient(D_X_loss, disc_X.trainable_variables)\n",
    "\n",
    "    # Apply gradients\n",
    "    G_optimizer.apply_gradients(zip(G_gradients, gen_G.trainable_variables))\n",
    "    F_optimizer.apply_gradients(zip(F_gradients, gen_F.trainable_variables))\n",
    "    D_Y_optimizer.apply_gradients(zip(D_Y_gradients, disc_Y.trainable_variables))\n",
    "    D_X_optimizer.apply_gradients(zip(D_X_gradients, disc_X.trainable_variables))\n",
    "\n",
    "    return {\n",
    "        \"G_loss\": G_total_loss,\n",
    "        \"F_loss\": F_total_loss,\n",
    "        \"D_Y_loss\": D_Y_loss,\n",
    "        \"D_X_loss\": D_X_loss\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:58:48.584097Z",
     "iopub.status.busy": "2025-06-22T17:58:48.583930Z",
     "iopub.status.idle": "2025-06-22T19:00:48.561003Z",
     "shell.execute_reply": "2025-06-22T19:00:48.560201Z",
     "shell.execute_reply.started": "2025-06-22T17:58:48.584083Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training execution\n",
    "num_epochs = 20\n",
    "checkpoint_dir = \"/kaggle/working/checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "g_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_g_loss = 0\n",
    "    total_steps = 0\n",
    "\n",
    "    for photo_batch, monet_batch in tf.data.Dataset.zip((photo_ds, monet_ds)):\n",
    "        losses = train_step(photo_batch, monet_batch)\n",
    "        total_g_loss += losses[\"G_loss\"]\n",
    "        total_steps += 1\n",
    "\n",
    "    avg_g_loss = total_g_loss / total_steps\n",
    "    g_losses.append(float(avg_g_loss))\n",
    "    print(f\"Epoch {epoch+1} - Avg G_loss: {avg_g_loss:.4f}\")\n",
    "    gen_G.save_weights(f\"{checkpoint_dir}/gen_G_epoch_{epoch+1}.weights.h5\")\n",
    "    gen_F.save_weights(f\"{checkpoint_dir}/gen_F_epoch_{epoch+1}.weights.h5\")\n",
    "    disc_X.save_weights(f\"{checkpoint_dir}/disc_X_epoch_{epoch+1}.weights.h5\")\n",
    "    disc_Y.save_weights(f\"{checkpoint_dir}/disc_Y_epoch_{epoch+1}.weights.h5\")\n",
    "    print(f\"Saved checkpoint at epoch {epoch+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:00:48.562239Z",
     "iopub.status.busy": "2025-06-22T19:00:48.561955Z",
     "iopub.status.idle": "2025-06-22T19:00:48.717043Z",
     "shell.execute_reply": "2025-06-22T19:00:48.716425Z",
     "shell.execute_reply.started": "2025-06-22T19:00:48.562214Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display loss over epochs\n",
    "plt.plot(g_losses)\n",
    "plt.title(\"Generator Loss Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Avg G_loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:00:48.717828Z",
     "iopub.status.busy": "2025-06-22T19:00:48.717626Z",
     "iopub.status.idle": "2025-06-22T19:07:55.689253Z",
     "shell.execute_reply": "2025-06-22T19:07:55.688471Z",
     "shell.execute_reply.started": "2025-06-22T19:00:48.717813Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate monet-styled images \n",
    "\n",
    "# Convert model output from [-1, 1] to [0, 255]\n",
    "def deprocess_image(img_tensor):\n",
    "    img = (img_tensor + 1.0) * 127.5\n",
    "    img = tf.clip_by_value(img, 0, 255)\n",
    "    return tf.cast(img, tf.uint8).numpy()\n",
    "\n",
    "# set up output directory\n",
    "output_dir = \"/kaggle/working/generated_monet\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# capture sample images\n",
    "num_display_samples = 5\n",
    "sample_pairs = []\n",
    "\n",
    "for i, photo_batch in enumerate(tqdm(photo_ds)):\n",
    "    generated = gen_G(photo_batch, training=False)[0]\n",
    "    output_img = deprocess_image(generated)\n",
    "    \n",
    "    output_path = os.path.join(output_dir, f\"{i+1:05d}.jpg\")\n",
    "    Image.fromarray(output_img).save(output_path)\n",
    "\n",
    "    if i < num_display_samples:\n",
    "        input_img = deprocess_image(photo_batch[0])\n",
    "        sample_pairs.append((input_img, output_img))\n",
    "\n",
    "# Display samples\n",
    "print(f\"\\nDisplaying {num_display_samples} sample Monet-style results:\")\n",
    "fig, axs = plt.subplots(num_display_samples, 2, figsize=(8, 2 * num_display_samples))\n",
    "\n",
    "for idx, (input_img, output_img) in enumerate(sample_pairs):\n",
    "    axs[idx, 0].imshow(input_img.astype(np.uint8))\n",
    "    axs[idx, 0].set_title(\"Original Photo\")\n",
    "    axs[idx, 0].axis(\"off\")\n",
    "\n",
    "    axs[idx, 1].imshow(output_img.astype(np.uint8))\n",
    "    axs[idx, 1].set_title(\"Monet-Style\")\n",
    "    axs[idx, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:07:55.690306Z",
     "iopub.status.busy": "2025-06-22T19:07:55.690064Z",
     "iopub.status.idle": "2025-06-22T19:07:56.398734Z",
     "shell.execute_reply": "2025-06-22T19:07:56.398118Z",
     "shell.execute_reply.started": "2025-06-22T19:07:55.690287Z"
    }
   },
   "outputs": [],
   "source": [
    "# Zip images\n",
    "zip_path = \"/kaggle/working/images.zip\"\n",
    "with zipfile.ZipFile(zip_path, \"w\") as zipf:\n",
    "    for filename in sorted(os.listdir(output_dir)):\n",
    "        file_path = os.path.join(output_dir, filename)\n",
    "        zipf.write(file_path, arcname=filename)\n",
    "\n",
    "print(f\"Saved {len(os.listdir(output_dir))} images to images.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This project implemented a **CycleGAN** model to perform unpaired image-to-image translation, converting real-world photos into **Monet-style paintings**.\n",
    "\n",
    "Over 20 training epochs, the generator showed consistent improvement in learning Monet's artistic style, as reflected in the decreasing generator loss\n",
    "\n",
    "\n",
    "The final model successfully generated over **7,000 Monet-style images**, which were packaged and submitted to the competition. The submission achieved a **Kaggle MiFID score of 95.186**, indicating strong quality and stylistic alignment with Monet's works.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- Used CycleGAN with identity and cycle-consistency loss to enable **unpaired translation**\n",
    "- Generator learned to preserve photo structure while applying Monet-style brushstrokes\n",
    "- Generator loss steadily improved, suggesting **stable convergence**\n",
    "- Final outputs are visually consistent and competition-ready\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 1475600,
     "sourceId": 21755,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
